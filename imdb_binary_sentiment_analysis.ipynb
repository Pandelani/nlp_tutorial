{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='resources/dl.jpg'>\n",
    "\n",
    "# Sentiment Analysis with Keras\n",
    "\n",
    "### Keras\n",
    "\n",
    "Keras is a deep learning library that focuses on providing a high level neural network API that comes with the best practicises included. It's ideal for beginners until you need more advanced features or know why or why you wont need the various best practices.\n",
    "\n",
    "### Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E: Could not open lock file /var/lib/dpkg/lock - open (13: Permission denied)\n",
      "E: Unable to lock the administration directory (/var/lib/dpkg/), are you root?\n",
      "Requirement already satisfied: graphviz in /usr/local/lib/python3.5/dist-packages\n",
      "Requirement already satisfied: pydot in /usr/local/lib/python3.5/dist-packages\n",
      "Requirement already satisfied: pyparsing>=2.1.4 in /usr/local/lib/python3.5/dist-packages (from pydot)\n"
     ]
    }
   ],
   "source": [
    "!apt-get install graphviz\n",
    "!pip install graphviz pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "\n",
    "import numpy as np\n",
    "import string\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense, Dropout, Embedding, LSTM, GRU, Bidirectional, Conv1D, GlobalMaxPooling1D\n",
    "from keras.datasets import imdb\n",
    "from keras.utils.vis_utils import model_to_dot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMDB Movie reviews sentiment classification\n",
    "\n",
    "Dataset of 25,000 movies reviews from IMDB, labeled by sentiment (positive/negative). Reviews have been preprocessed, and each review is encoded as a sequence of word indexes (integers). \n",
    "\n",
    "For convenience, words are indexed by overall frequency in the dataset, so that for instance the integer \"3\" encodes the 3rd most frequent word in the data. This allows for quick filtering operations such as: \"only consider the top 10,000 most common words, but eliminate the top 20 most common words\", by using the ```num_words``` argument.\n",
    "\n",
    "As a convention, \"0\" does not stand for a specific word, but instead is used to encode any unknown word.\n",
    "\n",
    "#### Special Tokens:\n",
    "\n",
    "```\n",
    "0: <PAD>\n",
    "1: <START>\n",
    "2: <UNKNOWN>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "number_of_words_tokenised = 20000\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=number_of_words_tokenised,\n",
    "                                                      index_from=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000 train sequences\n",
      "25000 test sequences\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that we have 25000 arbitrarily lengthed sentances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25000,), 218, 189)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, len(x_train[0]), len(x_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pad sequences (samples x time)\n",
      "x_train shape: (25000, 100)\n",
      "x_test shape: (25000, 100)\n"
     ]
    }
   ],
   "source": [
    "print('Pad sequences (samples x time)')\n",
    "# cut texts after this number of words\n",
    "# (among top max_features most common words)\n",
    "maxlen = 100\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the dataset\n",
    "\n",
    "Here we go from sequences of embedding indices to sentances and back again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_sentance_to_indices(sentance, \n",
    "                                max_sentance_length,\n",
    "                                word_to_index_dict, \n",
    "                                start_index=1, \n",
    "                                unknown_index=2,\n",
    "                                pad_index=0,\n",
    "                                remove_punctuation=False):\n",
    "    \n",
    "    if remove_punctuation:\n",
    "        strip_table = str.maketrans({key: None for key in string.punctuation})\n",
    "        sentance = sentance.translate(strip_table)\n",
    "        \n",
    "    indices = [start_index]\n",
    "    for word_count, word in enumerate(sentance.split()):\n",
    "        \n",
    "        if word_count >= max_sentance_length:\n",
    "            break\n",
    "            \n",
    "        try:\n",
    "            index = word_to_index_dict[word]\n",
    "        except:\n",
    "            index = unknown_index\n",
    "        indices.append(index)\n",
    "        \n",
    "    while len(indices) < max_sentance_length:\n",
    "        indices = [pad_index] + indices\n",
    "    \n",
    "    return indices\n",
    "\n",
    "\n",
    "def convert_indices_to_sentance(indices, index_to_word_dict):\n",
    "    words = [index_to_word_dict[index] for index in indices]\n",
    "    return \" \".join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_to_index_dict = imdb.get_word_index()\n",
    "word_to_index_dict = {key: (value + 3) for key, value in word_to_index_dict.items()}\n",
    "word_to_index_dict['<START>'] = 1\n",
    "word_to_index_dict['<PAD>'] = 0\n",
    "word_to_index_dict['<UNKNOWN>'] = 2\n",
    "\n",
    "index_to_word_dict = {value: key for key, value in word_to_index_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "** What the neural network will see: **\n",
      "[    0     0     0     0     0     0     0     0     0     0     1    14\n",
      "    22     9  1329     8    30     6   147  7942   894    25   391     4\n",
      "  2331   467    63    12    16    93     4    71  2218     8    30   177\n",
      "    11     4    22   310     7     6   297    15    16    24  1822   398\n",
      "    18    98    36    26   432     7  1147 16756    83     4   555  3614\n",
      "    12   238    28    77  2805    48    12    69   343   275   156    37\n",
      "   122    24    28   141   312  1398  2611   725    98   305    12    47\n",
      "    77  1437     2    17   173     7     6 10070     8    63    12    66\n",
      "   152  1833     8  4881]\n",
      "\n",
      "** What we humans like to see: **\n",
      "<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <START> this film is likely to be a real letdown unless you understand the circumstances under which it was made the were chosen to be cast in the film version of a play that was not originally written for them they are sort of force fitted into the roles ironically it might have been funnier if it had used different actors who did not have such high expectations placed upon them instead it has been forever <UNKNOWN> as part of a canon to which it really doesn't deserve to belong\n",
      "\n",
      "** What we want the neural network to predict: **\n",
      "0\n",
      "\n",
      "** The label is: **\n",
      "Negative\n"
     ]
    }
   ],
   "source": [
    "index = 100\n",
    "\n",
    "sentance = convert_indices_to_sentance(x_test[index], index_to_word_dict)\n",
    "label = y_test[index]\n",
    "\n",
    "print(\"\\n** What the neural network will see: **\")\n",
    "print(x_test[index])\n",
    "\n",
    "print(\"\\n** What we humans like to see: **\")\n",
    "print(sentance)\n",
    "\n",
    "print(\"\\n** What we want the neural network to predict: **\")\n",
    "print(label)\n",
    "\n",
    "print(\"\\n** The label is: **\")\n",
    "print(\"Positive\" if label == 1 else \"Negative\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making models is like playing with Lego\n",
    "\n",
    "\n",
    "Keras allows us to play with neural architecture lego blocks and stack things together in weird and wonderful ways. For now don't get bogged down in the theory of what works and doesn't work. Just be aware of what the shape each block needs as an input, and what the shape each block will output.\n",
    "\n",
    "<img src=\"resources/tower.jpg\" width=\"400\">\n",
    "\n",
    "Below are a bunch of models that you can try and extend, aswell as a blank function you could fill in with your own creation! [Feel free to browse the reference for available neural lego blocks to use.](https://keras.io/layers/about-keras-layers/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mlp(number_of_words_tokenised, sizes, keep_prob=0.2):\n",
    "    \n",
    "    model = Sequential()\n",
    "\n",
    "    # we start off with an efficient embedding layer which maps\n",
    "    # our vocab indices into embedding_dims dimensions.\n",
    "    model.add(Embedding(number_of_words_tokenised, 128, input_length=maxlen))\n",
    "    model.add(Dropout(keep_prob))\n",
    "\n",
    "    # For each size in the hidden sizes, add a vanilla hidden layer:\n",
    "    for size in sizes:\n",
    "        model.add(Dense(size))\n",
    "        model.add(Dropout(keep_prob))\n",
    "        model.add(Activation('relu'))\n",
    "\n",
    "    # We project onto a single unit output layer, and squash it with a sigmoid:\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def rnn(number_of_words_tokenised, rnn_type='lstm', hidden_size=64, keep_prob=0.5):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Embedding(number_of_words_tokenised, 128))\n",
    "    \n",
    "    if rnn_type is 'lstm':\n",
    "        rnn_cell = LSTM(hidden_size, dropout=keep_prob, recurrent_dropout=keep_prob)\n",
    "    else:\n",
    "        rnn_cell = GRU(hidden_size, dropout=keep_prob, recurrent_dropout=keep_prob)\n",
    "        \n",
    "    model.add(rnn_cell)\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def bidirectional_rnn(number_of_words_tokenised, rnn_type='lstm', hidden_size=64, keep_prob=0.5):\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Embedding(number_of_words_tokenised, 128, input_length=maxlen))\n",
    "    \n",
    "    rnn_cell = LSTM(hidden_size) if rnn_type is 'lstm' else GRU(hidden_size)\n",
    "    \n",
    "    model.add(Bidirectional(rnn_cell))\n",
    "    model.add(Dropout(keep_prob))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def convolutional(number_of_words_tokenised, filters=250, kernel_size=3, hidden_dims=250, keep_prob=0.2):\n",
    "    \n",
    "    model = Sequential()\n",
    "\n",
    "    # we start off with an efficient embedding layer which maps\n",
    "    # our vocab indices into embedding_dims dimensions\n",
    "    model.add(Embedding(number_of_words_tokenised, 128, input_length=maxlen))\n",
    "    model.add(Dropout(keep_prob))\n",
    "\n",
    "    # we add a Convolution1D, which will learn filters\n",
    "    # word group filters of size filter_length:\n",
    "    model.add(Conv1D(filters,\n",
    "                     kernel_size,\n",
    "                     padding='valid',\n",
    "                     activation='relu',\n",
    "                     strides=1))\n",
    "    # we use max pooling:\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "\n",
    "    # We add a vanilla hidden layer:\n",
    "    model.add(Dense(hidden_dims))\n",
    "    model.add(Dropout(keep_prob))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    # We project onto a single unit output layer, and squash it with a sigmoid:\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def my_model(number_of_words_tokenised):\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    # ... Insert code here ...\n",
    "    # Ensure that the model ends with a single\n",
    "    # sigmoidal unit.\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct desired model and view structure\n",
    "\n",
    "We choose the function we would like to construct our model and we then run it through a few helper functions to visualise the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"1134pt\" viewBox=\"0.00 0.00 339.00 1134.00\" width=\"339pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 1130)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-1130 335,-1130 335,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 140318207790328 -->\n",
       "<g class=\"node\" id=\"node1\"><title>140318207790328</title>\n",
       "<polygon fill=\"none\" points=\"0,-1079.5 0,-1125.5 331,-1125.5 331,-1079.5 0,-1079.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"96.5\" y=\"-1098.8\">embedding_3_input: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"193,-1079.5 193,-1125.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"220.5\" y=\"-1110.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"193,-1102.5 248,-1102.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"220.5\" y=\"-1087.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"248,-1079.5 248,-1125.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"289.5\" y=\"-1110.3\">(None, 100)</text>\n",
       "<polyline fill=\"none\" points=\"248,-1102.5 331,-1102.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"289.5\" y=\"-1087.3\">(None, 100)</text>\n",
       "</g>\n",
       "<!-- 140318207787304 -->\n",
       "<g class=\"node\" id=\"node2\"><title>140318207787304</title>\n",
       "<polygon fill=\"none\" points=\"2.5,-996.5 2.5,-1042.5 328.5,-1042.5 328.5,-996.5 2.5,-996.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"83\" y=\"-1015.8\">embedding_3: Embedding</text>\n",
       "<polyline fill=\"none\" points=\"163.5,-996.5 163.5,-1042.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"191\" y=\"-1027.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"163.5,-1019.5 218.5,-1019.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"191\" y=\"-1004.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"218.5,-996.5 218.5,-1042.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"273.5\" y=\"-1027.3\">(None, 100)</text>\n",
       "<polyline fill=\"none\" points=\"218.5,-1019.5 328.5,-1019.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"273.5\" y=\"-1004.3\">(None, 100, 128)</text>\n",
       "</g>\n",
       "<!-- 140318207790328&#45;&gt;140318207787304 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>140318207790328-&gt;140318207787304</title>\n",
       "<path d=\"M165.5,-1079.37C165.5,-1071.15 165.5,-1061.66 165.5,-1052.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"169,-1052.61 165.5,-1042.61 162,-1052.61 169,-1052.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140318207790832 -->\n",
       "<g class=\"node\" id=\"node3\"><title>140318207790832</title>\n",
       "<polygon fill=\"none\" points=\"20.5,-913.5 20.5,-959.5 310.5,-959.5 310.5,-913.5 20.5,-913.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"83\" y=\"-932.8\">dropout_5: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"145.5,-913.5 145.5,-959.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"173\" y=\"-944.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"145.5,-936.5 200.5,-936.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"173\" y=\"-921.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"200.5,-913.5 200.5,-959.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"255.5\" y=\"-944.3\">(None, 100, 128)</text>\n",
       "<polyline fill=\"none\" points=\"200.5,-936.5 310.5,-936.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"255.5\" y=\"-921.3\">(None, 100, 128)</text>\n",
       "</g>\n",
       "<!-- 140318207787304&#45;&gt;140318207790832 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>140318207787304-&gt;140318207790832</title>\n",
       "<path d=\"M165.5,-996.366C165.5,-988.152 165.5,-978.658 165.5,-969.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"169,-969.607 165.5,-959.607 162,-969.607 169,-969.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140318207788368 -->\n",
       "<g class=\"node\" id=\"node4\"><title>140318207788368</title>\n",
       "<polygon fill=\"none\" points=\"32,-830.5 32,-876.5 299,-876.5 299,-830.5 32,-830.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"83\" y=\"-849.8\">dense_6: Dense</text>\n",
       "<polyline fill=\"none\" points=\"134,-830.5 134,-876.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"161.5\" y=\"-861.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"134,-853.5 189,-853.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"161.5\" y=\"-838.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"189,-830.5 189,-876.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"244\" y=\"-861.3\">(None, 100, 128)</text>\n",
       "<polyline fill=\"none\" points=\"189,-853.5 299,-853.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"244\" y=\"-838.3\">(None, 100, 400)</text>\n",
       "</g>\n",
       "<!-- 140318207790832&#45;&gt;140318207788368 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>140318207790832-&gt;140318207788368</title>\n",
       "<path d=\"M165.5,-913.366C165.5,-905.152 165.5,-895.658 165.5,-886.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"169,-886.607 165.5,-876.607 162,-886.607 169,-886.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140318207890712 -->\n",
       "<g class=\"node\" id=\"node5\"><title>140318207890712</title>\n",
       "<polygon fill=\"none\" points=\"20.5,-747.5 20.5,-793.5 310.5,-793.5 310.5,-747.5 20.5,-747.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"83\" y=\"-766.8\">dropout_6: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"145.5,-747.5 145.5,-793.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"173\" y=\"-778.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"145.5,-770.5 200.5,-770.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"173\" y=\"-755.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"200.5,-747.5 200.5,-793.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"255.5\" y=\"-778.3\">(None, 100, 400)</text>\n",
       "<polyline fill=\"none\" points=\"200.5,-770.5 310.5,-770.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"255.5\" y=\"-755.3\">(None, 100, 400)</text>\n",
       "</g>\n",
       "<!-- 140318207788368&#45;&gt;140318207890712 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>140318207788368-&gt;140318207890712</title>\n",
       "<path d=\"M165.5,-830.366C165.5,-822.152 165.5,-812.658 165.5,-803.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"169,-803.607 165.5,-793.607 162,-803.607 169,-803.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140318207983912 -->\n",
       "<g class=\"node\" id=\"node6\"><title>140318207983912</title>\n",
       "<polygon fill=\"none\" points=\"9,-664.5 9,-710.5 322,-710.5 322,-664.5 9,-664.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"83\" y=\"-683.8\">activation_5: Activation</text>\n",
       "<polyline fill=\"none\" points=\"157,-664.5 157,-710.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"184.5\" y=\"-695.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"157,-687.5 212,-687.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"184.5\" y=\"-672.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"212,-664.5 212,-710.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"267\" y=\"-695.3\">(None, 100, 400)</text>\n",
       "<polyline fill=\"none\" points=\"212,-687.5 322,-687.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"267\" y=\"-672.3\">(None, 100, 400)</text>\n",
       "</g>\n",
       "<!-- 140318207890712&#45;&gt;140318207983912 -->\n",
       "<g class=\"edge\" id=\"edge5\"><title>140318207890712-&gt;140318207983912</title>\n",
       "<path d=\"M165.5,-747.366C165.5,-739.152 165.5,-729.658 165.5,-720.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"169,-720.607 165.5,-710.607 162,-720.607 169,-720.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140318436350888 -->\n",
       "<g class=\"node\" id=\"node7\"><title>140318436350888</title>\n",
       "<polygon fill=\"none\" points=\"32,-581.5 32,-627.5 299,-627.5 299,-581.5 32,-581.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"83\" y=\"-600.8\">dense_7: Dense</text>\n",
       "<polyline fill=\"none\" points=\"134,-581.5 134,-627.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"161.5\" y=\"-612.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"134,-604.5 189,-604.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"161.5\" y=\"-589.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"189,-581.5 189,-627.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"244\" y=\"-612.3\">(None, 100, 400)</text>\n",
       "<polyline fill=\"none\" points=\"189,-604.5 299,-604.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"244\" y=\"-589.3\">(None, 100, 400)</text>\n",
       "</g>\n",
       "<!-- 140318207983912&#45;&gt;140318436350888 -->\n",
       "<g class=\"edge\" id=\"edge6\"><title>140318207983912-&gt;140318436350888</title>\n",
       "<path d=\"M165.5,-664.366C165.5,-656.152 165.5,-646.658 165.5,-637.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"169,-637.607 165.5,-627.607 162,-637.607 169,-637.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140318178516104 -->\n",
       "<g class=\"node\" id=\"node8\"><title>140318178516104</title>\n",
       "<polygon fill=\"none\" points=\"20.5,-498.5 20.5,-544.5 310.5,-544.5 310.5,-498.5 20.5,-498.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"83\" y=\"-517.8\">dropout_7: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"145.5,-498.5 145.5,-544.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"173\" y=\"-529.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"145.5,-521.5 200.5,-521.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"173\" y=\"-506.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"200.5,-498.5 200.5,-544.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"255.5\" y=\"-529.3\">(None, 100, 400)</text>\n",
       "<polyline fill=\"none\" points=\"200.5,-521.5 310.5,-521.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"255.5\" y=\"-506.3\">(None, 100, 400)</text>\n",
       "</g>\n",
       "<!-- 140318436350888&#45;&gt;140318178516104 -->\n",
       "<g class=\"edge\" id=\"edge7\"><title>140318436350888-&gt;140318178516104</title>\n",
       "<path d=\"M165.5,-581.366C165.5,-573.152 165.5,-563.658 165.5,-554.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"169,-554.607 165.5,-544.607 162,-554.607 169,-554.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140318178513136 -->\n",
       "<g class=\"node\" id=\"node9\"><title>140318178513136</title>\n",
       "<polygon fill=\"none\" points=\"9,-415.5 9,-461.5 322,-461.5 322,-415.5 9,-415.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"83\" y=\"-434.8\">activation_6: Activation</text>\n",
       "<polyline fill=\"none\" points=\"157,-415.5 157,-461.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"184.5\" y=\"-446.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"157,-438.5 212,-438.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"184.5\" y=\"-423.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"212,-415.5 212,-461.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"267\" y=\"-446.3\">(None, 100, 400)</text>\n",
       "<polyline fill=\"none\" points=\"212,-438.5 322,-438.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"267\" y=\"-423.3\">(None, 100, 400)</text>\n",
       "</g>\n",
       "<!-- 140318178516104&#45;&gt;140318178513136 -->\n",
       "<g class=\"edge\" id=\"edge8\"><title>140318178516104-&gt;140318178513136</title>\n",
       "<path d=\"M165.5,-498.366C165.5,-490.152 165.5,-480.658 165.5,-471.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"169,-471.607 165.5,-461.607 162,-471.607 169,-471.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140318178514592 -->\n",
       "<g class=\"node\" id=\"node10\"><title>140318178514592</title>\n",
       "<polygon fill=\"none\" points=\"32,-332.5 32,-378.5 299,-378.5 299,-332.5 32,-332.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"83\" y=\"-351.8\">dense_8: Dense</text>\n",
       "<polyline fill=\"none\" points=\"134,-332.5 134,-378.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"161.5\" y=\"-363.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"134,-355.5 189,-355.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"161.5\" y=\"-340.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"189,-332.5 189,-378.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"244\" y=\"-363.3\">(None, 100, 400)</text>\n",
       "<polyline fill=\"none\" points=\"189,-355.5 299,-355.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"244\" y=\"-340.3\">(None, 100, 400)</text>\n",
       "</g>\n",
       "<!-- 140318178513136&#45;&gt;140318178514592 -->\n",
       "<g class=\"edge\" id=\"edge9\"><title>140318178513136-&gt;140318178514592</title>\n",
       "<path d=\"M165.5,-415.366C165.5,-407.152 165.5,-397.658 165.5,-388.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"169,-388.607 165.5,-378.607 162,-388.607 169,-388.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140318178463416 -->\n",
       "<g class=\"node\" id=\"node11\"><title>140318178463416</title>\n",
       "<polygon fill=\"none\" points=\"20.5,-249.5 20.5,-295.5 310.5,-295.5 310.5,-249.5 20.5,-249.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"83\" y=\"-268.8\">dropout_8: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"145.5,-249.5 145.5,-295.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"173\" y=\"-280.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"145.5,-272.5 200.5,-272.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"173\" y=\"-257.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"200.5,-249.5 200.5,-295.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"255.5\" y=\"-280.3\">(None, 100, 400)</text>\n",
       "<polyline fill=\"none\" points=\"200.5,-272.5 310.5,-272.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"255.5\" y=\"-257.3\">(None, 100, 400)</text>\n",
       "</g>\n",
       "<!-- 140318178514592&#45;&gt;140318178463416 -->\n",
       "<g class=\"edge\" id=\"edge10\"><title>140318178514592-&gt;140318178463416</title>\n",
       "<path d=\"M165.5,-332.366C165.5,-324.152 165.5,-314.658 165.5,-305.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"169,-305.607 165.5,-295.607 162,-305.607 169,-305.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140318178552912 -->\n",
       "<g class=\"node\" id=\"node12\"><title>140318178552912</title>\n",
       "<polygon fill=\"none\" points=\"9,-166.5 9,-212.5 322,-212.5 322,-166.5 9,-166.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"83\" y=\"-185.8\">activation_7: Activation</text>\n",
       "<polyline fill=\"none\" points=\"157,-166.5 157,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"184.5\" y=\"-197.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"157,-189.5 212,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"184.5\" y=\"-174.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"212,-166.5 212,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"267\" y=\"-197.3\">(None, 100, 400)</text>\n",
       "<polyline fill=\"none\" points=\"212,-189.5 322,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"267\" y=\"-174.3\">(None, 100, 400)</text>\n",
       "</g>\n",
       "<!-- 140318178463416&#45;&gt;140318178552912 -->\n",
       "<g class=\"edge\" id=\"edge11\"><title>140318178463416-&gt;140318178552912</title>\n",
       "<path d=\"M165.5,-249.366C165.5,-241.152 165.5,-231.658 165.5,-222.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"169,-222.607 165.5,-212.607 162,-222.607 169,-222.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140318207790384 -->\n",
       "<g class=\"node\" id=\"node13\"><title>140318207790384</title>\n",
       "<polygon fill=\"none\" points=\"32,-83.5 32,-129.5 299,-129.5 299,-83.5 32,-83.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"83\" y=\"-102.8\">dense_9: Dense</text>\n",
       "<polyline fill=\"none\" points=\"134,-83.5 134,-129.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"161.5\" y=\"-114.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"134,-106.5 189,-106.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"161.5\" y=\"-91.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"189,-83.5 189,-129.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"244\" y=\"-114.3\">(None, 100, 400)</text>\n",
       "<polyline fill=\"none\" points=\"189,-106.5 299,-106.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"244\" y=\"-91.3\">(None, 100, 1)</text>\n",
       "</g>\n",
       "<!-- 140318178552912&#45;&gt;140318207790384 -->\n",
       "<g class=\"edge\" id=\"edge12\"><title>140318178552912-&gt;140318207790384</title>\n",
       "<path d=\"M165.5,-166.366C165.5,-158.152 165.5,-148.658 165.5,-139.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"169,-139.607 165.5,-129.607 162,-139.607 169,-139.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140318222890768 -->\n",
       "<g class=\"node\" id=\"node14\"><title>140318222890768</title>\n",
       "<polygon fill=\"none\" points=\"15.5,-0.5 15.5,-46.5 315.5,-46.5 315.5,-0.5 15.5,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"89.5\" y=\"-19.8\">activation_8: Activation</text>\n",
       "<polyline fill=\"none\" points=\"163.5,-0.5 163.5,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"191\" y=\"-31.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"163.5,-23.5 218.5,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"191\" y=\"-8.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"218.5,-0.5 218.5,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"267\" y=\"-31.3\">(None, 100, 1)</text>\n",
       "<polyline fill=\"none\" points=\"218.5,-23.5 315.5,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"267\" y=\"-8.3\">(None, 100, 1)</text>\n",
       "</g>\n",
       "<!-- 140318207790384&#45;&gt;140318222890768 -->\n",
       "<g class=\"edge\" id=\"edge13\"><title>140318207790384-&gt;140318222890768</title>\n",
       "<path d=\"M165.5,-83.3664C165.5,-75.1516 165.5,-65.6579 165.5,-56.7252\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"169,-56.6068 165.5,-46.6068 162,-56.6069 169,-56.6068\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = mlp(number_of_words_tokenised, sizes=[400, 400, 400])\n",
    "# model = rnn(number_of_words_tokenised)\n",
    "# model = bidirectional_rnn(number_of_words_tokenised)\n",
    "# model = convolutional(number_of_words_tokenised)\n",
    "# model = my_model(number_of_words_tokenised)\n",
    "\n",
    "SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binary Cross entropy is defined as:\n",
    "$$-{(y\\log(p) + (1 - y)\\log(1 - p))}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try using different optimizers and different optimizer configs\n",
    "model.compile('adam', 'binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected activation_8 to have 3 dimensions, but got array with shape (25000, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-28f5557f6700>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m           validation_data=[x_test, y_test])\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    865\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 867\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1520\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1521\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1522\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1523\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1524\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)\u001b[0m\n\u001b[1;32m   1380\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1381\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m                                     exception_prefix='target')\n\u001b[0m\u001b[1;32m   1383\u001b[0m         sample_weights = _standardize_sample_weights(sample_weight,\n\u001b[1;32m   1384\u001b[0m                                                      self._feed_output_names)\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    130\u001b[0m                                  \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m                                  \u001b[0;34m' dimensions, but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m                                  str(array.shape))\n\u001b[0m\u001b[1;32m    133\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_dim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected activation_8 to have 3 dimensions, but got array with shape (25000, 1)"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "epochs = 4\n",
    "\n",
    "model.fit(x_train, \n",
    "          y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=[x_test, y_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the model!\n",
    "\n",
    "The first step is to create a bunch of sentances that are either positive or negative. The model will then predict this. Because the model ends with a single sigmoidal neuron, which means the value it will output will be squashed between zero and one, we can simply binarise the value by checking if it is greater than 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. 'good movie' was a positive sentance\n",
      "1. 'bad movie' was a negative sentance\n",
      "2. 'I hate big corporations, especially tech companies like facebook.' was a negative sentance\n",
      "3. 'I love being a contrarian.' was a positive sentance\n",
      "4. 'Argh! Fuck this!' was a positive sentance\n",
      "5. 'To be honest this was a fun thing.' was a positive sentance\n",
      "6. 'Just tried watching Modern Family - written by a moron, really boring. Writer has the mind of a very dumb and backward child.' was a negative sentance\n",
      "7. 'I look very much forward to showing my financials, because they are huge.' was a positive sentance\n"
     ]
    }
   ],
   "source": [
    "test_sentances = []\n",
    "\n",
    "test_sentances.append(\"good movie\")\n",
    "test_sentances.append(\"bad movie\")\n",
    "test_sentances.append(\"I hate big corporations, especially tech companies like facebook.\")\n",
    "test_sentances.append(\"I love being a contrarian.\")\n",
    "test_sentances.append(\"Argh! Fuck this!\")\n",
    "test_sentances.append(\"To be honest this was a fun thing.\")\n",
    "test_sentances.append(\"Just tried watching Modern Family - written by a moron, really boring. Writer has the mind of a very dumb and backward child.\")\n",
    "test_sentances.append(\"I look very much forward to showing my financials, because they are huge.\")\n",
    "\n",
    "for i, test_sentance in enumerate(test_sentances):\n",
    "    \n",
    "    test_sentance_indices = convert_sentance_to_indices(test_sentance, \n",
    "                                                        maxlen, \n",
    "                                                        word_to_index_dict)\n",
    "    test_sentance_indices = np.array(test_sentance_indices).reshape((1, -1))\n",
    "\n",
    "    prediction = model.predict(x=test_sentance_indices)[0]\n",
    "\n",
    "    if prediction < 0.5:\n",
    "        print(\"{}. '{}' was a negative sentance\".format(i, test_sentance))\n",
    "    else:\n",
    "        print(\"{}. '{}' was a positive sentance\".format(i, test_sentance))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
